<!DOCTYPE html>
<html>
<head>
  <title>WebLLM Text to HTML</title>
</head>
<body>

  <script>


    

myLLM = async function(){       // note how the brakets for passing variables is removed from the function name                                                          
  const messages = [{ role: 'user', content: 'What is rome' }];
  const reply = await engineInstance.chat.completions.create({ messages });
  console.log(reply.choices[0].message.content);
  document.getElementById('htmlOutput').innerHTML = 'hi'
} 
  </script>

  <h1>WebLLM Text to HTML</h1>


  <textarea id="textInput" rows="10" cols="50" placeholder="Enter your text here, then click button after the model has loaded..."></textarea><br><br>


  <input type=button value="Generate HTML" onclick="{ myLLM() }">

  <div id="htmlOutput"></div>

<script type="module">
import { CreateMLCEngine, MLCEngine } from "https://esm.run/@mlc-ai/web-llm";

 // Initialize with a progress callback
 const initProgressCallback = (progress) => {
     console.log("Model loading progress:", progress);
     document.getElementById('htmlOutput').innerHTML = `Model loading progress: ${progress}`
 };

// Using CreateMLCEngine
const engine = await CreateMLCEngine("Llama-3.2-1B-Instruct-q4f16_1-MLC", { initProgressCallback });

// Direct instantiation
const engineInstance = new MLCEngine({ initProgressCallback });
await engineInstance.reload("Llama-3.2-1B-Instruct-q4f16_1-MLC");

const messages = [{ role: "user", content: "How does WebLLM use workers?" }];
const reply = await engineInstance.chat.completions.create({ messages });
console.log(reply.choices[0].message.content);



</script>

</body>
</html>
