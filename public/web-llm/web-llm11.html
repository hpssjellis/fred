<!DOCTYPE html>
<html>
<head>
  <title>WebLLM Text to HTML</title>
</head>
<body>

  <script type="module">
    import { CreateMLCEngine, MLCEngine } from "https://esm.run/@mlc-ai/web-llm";

    // Declare the variable globally
    let engineInstance;

    // Initialize with a progress callback
    const initProgressCallback = (progress) => {
      console.log("Model loading progress:", progress);
      document.getElementById('htmlOutput').innerHTML = `Model loading progress: ${progress[progress.length].text}`;
    };

    // Using CreateMLCEngine
    const engine = await CreateMLCEngine("Llama-3.2-1B-Instruct-q4f16_1-MLC", { initProgressCallback });

    // Direct instantiation
    engineInstance = new MLCEngine({ initProgressCallback });
    await engineInstance.reload("Llama-3.2-1B-Instruct-q4f16_1-MLC");

    const messages = [{ role: "user", content: "How does WebLLM use workers?" }];
    const reply = await engineInstance.chat.completions.create({ messages });
    console.log(reply.choices[0].message.content);
  </script>

  <h1>WebLLM Text to HTML</h1>

  <textarea id="textInput" rows="10" cols="50" placeholder="Enter your text here, then click button after the model has loaded..."></textarea><br><br>

  <input type="button" value="Generate HTML" onclick="myLLM()">

  <div id="htmlOutput"></div>

  <script>
    async function myLLM() {
      const messages = [{ role: 'user', content: 'What is rome' }];
      const reply = await engineInstance.chat.completions.create({ messages });
      console.log(reply.choices[0].message.content);
      document.getElementById('htmlOutput').innerHTML = reply.choices[0].message.content;
    }
  </script>

</body>
</html>
