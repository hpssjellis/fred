<!DOCTYPE html>
<html>
<head>
    <title>Personal Webpage Security</title>
    <style>
        body { font-family: Arial; text-align: center; margin-top: 50px; }
        video { border: 1px solid black; }
        #progress { width: 300px; height: 10px; background-color: #ddd; }
        #progress .fill { background-color: green; width: 0%; }
    </style>
</head>
<body>
    <h1>Personal Webpage Security</h1>
    <div id="training">
        <video id="myVideo" autoplay></video><br>
        <button onclick="captureImage()">Capture Training Image</button>
        <button onclick="trainModel()">Train Model</button>
        <p id="trainingMessage"></p>
        <div id="progress">
            <div id="progressBar" class="fill"></div>
        </div>
    </div>
    <div id="auth" style="display:none;">
        <video id="myAuthVideo" autoplay></video><br>
        <button onclick="authenticate()">Authenticate</button>
        <p id="authMessage"></p>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script>
        let myVideo = document.getElementById('myVideo');
        let myAuthVideo = document.getElementById('myAuthVideo');
        let myTrainingImages = [];
        let myModel;

        // Initialize webcam
        async function initWebcam(videoElement) {
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            videoElement.srcObject = stream;
        }
        initWebcam(myVideo);

        // Capture a training image with preprocessing
        function captureImage() {
            const canvas = document.createElement('canvas');
            canvas.width = myVideo.videoWidth;
            canvas.height = myVideo.videoHeight;
            const ctx = canvas.getContext('2d');
            ctx.drawImage(myVideo, 0, 0);
            const imageData = tf.browser.fromPixels(canvas).toFloat().div(255.0); // Normalize pixel values
            myTrainingImages.push(imageData);
            document.getElementById('trainingMessage').innerText = `Captured ${myTrainingImages.length} images`;
        }

        // Train the model
        async function trainModel() {
            if (myTrainingImages.length < 10) {
                document.getElementById('trainingMessage').innerText = 'Capture more training images!';
                return;
            }

            const labels = myTrainingImages.map((_, i) => i < myTrainingImages.length / 2 ? 1 : 0); // Binary labels
            const xs = tf.stack(myTrainingImages);
            const ys = tf.tensor(labels);

            myModel = tf.sequential();
            myModel.add(tf.layers.conv2d({
                filters: 32,
                kernelSize: 3,
                activation: 'relu',
                inputShape: [xs.shape[1], xs.shape[2], 3] // Assuming grayscale images
            }));
            myModel.add(tf.layers.maxPooling2d({ poolSize: 2 }));
            myModel.add(tf.layers.flatten());
            myModel.add(tf.layers.dense({ units: 128, activation: 'relu' }));
            myModel.add(tf.layers.dense({ units: 1, activation: 'sigmoid' }));

            myModel.compile({ optimizer: 'adam', loss: 'binaryCrossentropy', metrics: ['accuracy'] });

            const onEpochEnd = (epoch, logs) => {
                const progress = (epoch + 1) / 10 * 100; // Assuming 10 epochs
                document.getElementById('progressBar').style.width = progress + '%';
            };

            await myModel.fit(xs, ys, { epochs: 10, callbacks: { onEpochEnd: onEpochEnd } });
            await myModel.save('localstorage://my-personal-model');
            document.getElementById('trainingMessage').innerText = 'Model trained and saved!';
        }

        // Authenticate the user
        async function authenticate() {
            const canvas = document.createElement('canvas');
            canvas.width = myAuthVideo.videoWidth;
            canvas.height = myAuthVideo.videoHeight;
            const ctx = canvas.getContext('2d');
            ctx.drawImage(myAuthVideo, 0, 0);
            const imageData = tf.browser.fromPixels(canvas).toFloat().div(255.0); // Normalize

            try {
                myModel = await tf.loadLayersModel('localstorage://my-personal-model');
                const prediction = myModel.predict(imageData.expandDims(0)).dataSync()[0];
                if (prediction > 0.7) { // Adjust threshold as needed
                    document.getElementById('authMessage').innerText = 'Access Granted!';
                    document.getElementById('auth').style.display = 'none';
                    document.body.style.background = 'lightgreen';
                } else {
                    document.getElementById('authMessage').innerText = 'Access Denied!';
                }
            } catch (error) {
                document.getElementById('authMessage').innerText = 'Error loading model.';
            }
        }

        // Initialize webcam for authentication
        initWebcam(myAuthVideo);

    </script>
</body>
</html>                  
