<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Face Detection with face-api.js</title>
  <!-- Load face-api.js -->
  <script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  <!-- Load additional libraries if needed -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <style>
    .canvas-wrapper {
      display: inline-block;
      position: relative;
    }
    #video {
      -webkit-transform: scaleX(-1);
      transform: scaleX(-1);
      visibility: hidden;
      width: auto;
      height: auto;
    }
    #output {
      position: absolute;
      top: 0;
      left: 0;
    }
  </style>
</head>
<body>
  <div class="canvas-wrapper">
    <video id="video" playsinline autoplay></video>
    <canvas id="output"></canvas>
  </div>
  <div id="log"></div>










    <script>
    // Utility function to check if the device is mobile
    function isMobile() {
      return /Android|iPhone|iPad|iPod/i.test(navigator.userAgent);
    }

    // Function to log messages to the log div
    function logMessage(message) {
      const logDiv = document.getElementById('log');
      logDiv.innerHTML += `<p>${message}</p>`;
    }

    // Function to set up the camera
    async function setupCamera() {
      const video = document.getElementById('video');
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: 'user' },
        audio: false
      });
      video.srcObject = stream;
      return new Promise((resolve) => {
        video.onloadedmetadata = () => {
          resolve(video);
        };
      });
    }








          // Function to load face-api.js models
    async function loadModels() {
      const MODEL_URL = '/models';
      await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
      await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
      await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);
      logMessage('Models loaded');
    }

    // Function to start face detection
    async function startFaceDetection() {
      const video = await setupCamera();
      video.play();

      const canvas = document.getElementById('output');
      const displaySize = { width: video.videoWidth, height: video.videoHeight };
      faceapi.matchDimensions(canvas, displaySize);

      setInterval(async () => {
        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceDescriptors();
        const resizedDetections = faceapi.resizeResults(detections, displaySize);
        canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
        faceapi.draw.drawDetections(canvas, resizedDetections);
        faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
      }, 100);
    }

    // Initialize the application
    async function init() {
      logMessage('Initializing application');
      await loadModels();
      await startFaceDetection();
    }

    // Start the application
    window.addEventListener('DOMContentLoaded', init);
  </script>
</body>
</html>
