<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Audio Waveform Visualizer</title>
</head>
<body>
    <canvas id="audioCanvas" width="800" height="300" style="border:1px solid black;"></canvas>
    <button id="myStart3" onclick="startRecording(3)">Record Channel 3</button>
    <button onclick="stopRecording(3, 'myName3')">Stop Channel 3</button>
    <script>

const audioContext = new (window.AudioContext || window.webkitAudioContext)();
const analyser = audioContext.createAnalyser();
const canvas = document.getElementById('audioCanvas');
const canvasCtx = canvas.getContext('2d');



let shouldVisualize = false;  // Flag to control visualization

function visualize() {
    analyser.fftSize = 2048;
    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);

    function draw() {
        if (!shouldVisualize) return;  // Stop drawing if the flag is false
        requestAnimationFrame(draw);

        analyser.getByteTimeDomainData(dataArray);

        canvasCtx.fillStyle = 'rgb(200, 200, 200)';
        canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

        canvasCtx.lineWidth = 2;
        canvasCtx.strokeStyle = 'rgb(0, 0, 0)';

        canvasCtx.beginPath();

        var sliceWidth = canvas.width * 1.0 / bufferLength;
        var x = 0;

        for (let i = 0; i < bufferLength; i++) {
            var v = dataArray[i] / 128.0;
            var y = v * canvas.height / 2;

            if (i === 0) {
                canvasCtx.moveTo(x, y);
            } else {
                canvasCtx.lineTo(x, y);
            }

            x += sliceWidth;
        }

        canvasCtx.lineTo(canvas.width, canvas.height / 2);
        canvasCtx.stroke();
    }

    shouldVisualize = true;  // Set the flag to true when starting
    draw();
}

function stopRecording(channel, myFileName) {
    mediaRecorders[channel].stop();
    mediaRecorders[channel].onstop = () => {
        shouldVisualize = false;  // Set the flag to false to stop the visualization
        // Handle audio blob and download link setup here...
    };
}



      

function startRecording(channel) {
    navigator.mediaDevices.getUserMedia({ audio: true })
    .then(stream => {
        const mediaStreamSource = audioContext.createMediaStreamSource(stream);
        mediaStreamSource.connect(analyser);
        shouldVisualize = true;  // Ensure visualization starts
        visualize();
        // Additional setup...
    })
    .catch(error => {
        console.error("Error accessing media devices.", error);
    });
}


// Add your stopRecording and other necessary functions as per your application's requirements.


        
    </script>
</body>
</html>
